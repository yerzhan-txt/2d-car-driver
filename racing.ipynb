{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98825a7a-b61e-4f84-8f49-276c1bb9d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/z5288866/.venvs/pnd_env/lib/python3.9/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3863fdbf-d191-4a59-8c0e-ea928685b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# racing_env.py\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DiscreteRacingEnv(gym.Env):\n",
    "    def __init__(self, path_file='path.npy', track_radius=0.2, n_sensors=5):\n",
    "        super().__init__()\n",
    "        self.centerline = np.load(path_file)\n",
    "        self.centerline = self.centerline - np.mean(self.centerline, axis=0)\n",
    "        self.centerline = self.centerline / np.max(np.abs(self.centerline))\n",
    "        self.track_radius = track_radius\n",
    "        self.center = np.mean(self.centerline, axis=0)\n",
    "\n",
    "        # Sensor configuration\n",
    "        self.sensor_angles = np.linspace(-np.pi/4, np.pi/4, n_sensors)\n",
    "        self.observation_space = spaces.Box(low=0, high=3.0, shape=(n_sensors,), dtype=np.float32)\n",
    "\n",
    "        # Discrete action space: 5 steering x 3 throttle = 15 total actions\n",
    "        self.steering_bins = [-0.5, -0.25, 0.0, 0.25, 0.5]\n",
    "        self.throttle_bins = [-0.5, 0.0, 0.5]\n",
    "        self.action_space = spaces.Discrete(len(self.steering_bins) * len(self.throttle_bins))\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def decode_action(self, action):\n",
    "        steer_idx = action % len(self.steering_bins)\n",
    "        throttle_idx = action // len(self.steering_bins)\n",
    "        return self.steering_bins[steer_idx], self.throttle_bins[throttle_idx]\n",
    "\n",
    "    def reset(self):\n",
    "        self.car_pos = np.copy(self.centerline[0])\n",
    "        self.car_vel = 0.1\n",
    "        self.car_angle = np.pi / 2  # face upward\n",
    "        self.done = False\n",
    "        self.passed_checkpoints = np.zeros(len(self.centerline), dtype=bool)\n",
    "        return self.get_observation()\n",
    "\n",
    "    def is_on_track(self, point):\n",
    "        return np.any(np.linalg.norm(self.centerline - point, axis=1) < self.track_radius)\n",
    "\n",
    "    def get_observation(self):\n",
    "        distances = []\n",
    "        for offset in self.sensor_angles:\n",
    "            direction = np.array([\n",
    "                np.cos(self.car_angle + offset),\n",
    "                np.sin(self.car_angle + offset)\n",
    "            ])\n",
    "            for d in np.linspace(0, 3.0, 30):\n",
    "                probe = self.car_pos + d * direction\n",
    "                if not self.is_on_track(probe):\n",
    "                    distances.append(d)\n",
    "                    break\n",
    "            else:\n",
    "                distances.append(3.0)\n",
    "        return np.array(distances, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        steer, throttle = self.decode_action(action)\n",
    "        self.car_angle += steer * 0.1\n",
    "        self.car_vel = np.clip(self.car_vel + throttle * 0.01, 0.05, 0.2)\n",
    "        forward = np.array([np.cos(self.car_angle), np.sin(self.car_angle)])\n",
    "        self.car_pos += self.car_vel * forward\n",
    "\n",
    "        if not self.is_on_track(self.car_pos):\n",
    "            self.done = True\n",
    "            return self.get_observation(), -10.0, self.done, {}\n",
    "\n",
    "        # Checkpoints and direction reward\n",
    "        for i, point in enumerate(self.centerline):\n",
    "            if not self.passed_checkpoints[i] and np.linalg.norm(self.car_pos - point) < self.track_radius / 2:\n",
    "                self.passed_checkpoints[i] = True\n",
    "\n",
    "        r = self.car_pos - self.center\n",
    "        cross_z = r[0] * forward[1] - r[1] * forward[0]\n",
    "        rotation_reward = np.sign(cross_z) * 1.0\n",
    "\n",
    "        progress = np.sum(self.passed_checkpoints) / len(self.centerline)\n",
    "        reward = self.car_vel + 2.0 * progress + rotation_reward\n",
    "        return self.get_observation(), reward, self.done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(self.centerline[:, 0], self.centerline[:, 1], 'k--')\n",
    "        for p in self.centerline:\n",
    "            ax.add_patch(plt.Circle(p, self.track_radius, color='lightgray', alpha=0.3))\n",
    "        ax.plot(self.car_pos[0], self.car_pos[1], 'ro')\n",
    "        ax.plot(self.center[0], self.center[1], 'gx')\n",
    "        plt.axis('equal')\n",
    "        plt.close(fig)\n",
    "        return fig\n",
    "\n",
    "# Training config parameters (can be imported into training script)\n",
    "TRAINING_CONFIG = {\n",
    "    \"total_timesteps\": 200_000,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.99\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de68df22-e899-4f17-b2ae-57fa4b2ddcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 13:33:34.525976: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Your environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(mode)\n\u001b[1;32m     23\u001b[0m env \u001b[38;5;241m=\u001b[39m RacingWrapper()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mcheck_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     env,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ppo_racing_tensorboard/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39mTRAINING_CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_timesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.venvs/pnd_env/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:429\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_env\u001b[39m(env: gym\u001b[38;5;241m.\u001b[39mEnv, warn: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, skip_render_check: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    Check that an environment follows Gym API.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    This is particularly useful when using a custom environment.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m        True by default (useful for the CI)\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    430\u001b[0m         env, gym\u001b[38;5;241m.\u001b[39mEnv\n\u001b[1;32m    431\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;66;03m# ============= Check the spaces (observation and action) ================\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     _check_spaces(env)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from racing_env import DiscreteRacingEnv, TRAINING_CONFIG\n",
    "\n",
    "# Register custom env with Gym\n",
    "class RacingWrapper(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.env = DiscreteRacingEnv()\n",
    "        self.observation_space = self.env.observation_space\n",
    "        self.action_space = self.env.action_space\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return self.env.render(mode)\n",
    "\n",
    "env = RacingWrapper()\n",
    "check_env(env, warn=True)\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=TRAINING_CONFIG[\"learning_rate\"],\n",
    "    n_steps=TRAINING_CONFIG[\"n_steps\"],\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    n_epochs=TRAINING_CONFIG[\"n_epochs\"],\n",
    "    gamma=TRAINING_CONFIG[\"gamma\"],\n",
    "    tensorboard_log=\"./ppo_racing_tensorboard/\"\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=TRAINING_CONFIG[\"total_timesteps\"])\n",
    "model.save(\"ppo_racing_agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34008a-b344-4e74-aa08-915979b53f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from racing_env import DiscreteRacingEnv\n",
    "\n",
    "# Load environment and trained model\n",
    "env = DiscreteRacingEnv()\n",
    "model = PPO.load(\"ppo_racing_agent\")\n",
    "\n",
    "# Prepare video writer\n",
    "writer = imageio.get_writer(\"racing_demo.mp4\", fps=30, codec='libx264')\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "\n",
    "    fig = env.render()\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    writer.append_data(image)\n",
    "    plt.close(fig)\n",
    "\n",
    "writer.close()\n",
    "print(\"âœ… Saved racing_demo.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
